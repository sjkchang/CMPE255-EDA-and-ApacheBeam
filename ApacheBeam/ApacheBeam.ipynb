{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m98m_qoOoX1t"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet apache-beam\n",
        "!pip install --quiet apache-beam[interactive]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "import re"
      ],
      "metadata": {
        "id": "umW3975upKUX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/InputFiles/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DK0ZsFi2AQs",
        "outputId": "47bee315-1494-4de8-f49a-db45a78cedf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/InputFiles\n",
            "input1.txt  input2.txt  input3.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline IO**"
      ],
      "metadata": {
        "id": "rdXSnVjepzBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline will lowercase each word in all of the lines of the input text"
      ],
      "metadata": {
        "id": "-iiLHlFPxzKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = beam.Pipeline()\n",
        "\n",
        "(p | 'Read from Text' >> beam.io.ReadFromText('input1.txt')\n",
        "   | 'Lowercase each Words' >> beam.Map(lambda x: x.lower())\n",
        "   | 'Write to Text' >> beam.io.WriteToText('output-pipeline', file_name_suffix='.txt'))\n",
        "\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9HuvYktPr1eb",
        "outputId": "10988c46-80f9-48bf-a278-6e4caefb241a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7d0f04806ce0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pardo**"
      ],
      "metadata": {
        "id": "NLm4qiibp31E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ParDo is a parallel processing operation. This line tokenizes each line from the text files into individual words.\n"
      ],
      "metadata": {
        "id": "0JHOqnQqzTM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitIntoWords(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        return element.split()\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "(p | 'Read from Text' >> beam.io.ReadFromText('input1.txt')\n",
        "   | 'Split into Words' >> beam.ParDo(SplitIntoWords())\n",
        "   | 'Write to Text' >> beam.io.WriteToText('output-pardo', file_name_suffix='.txt'))\n",
        "\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXCubNXxsDFI",
        "outputId": "4b72ff96-1d2f-4489-9b56-1ee308d7c2b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7d0f032a27d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Composite Transform**"
      ],
      "metadata": {
        "id": "e2NVZfMcpw3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Composite transform is a powerful concept in Apache Beam that allow you to encapsulate a sequence of transformations into a single, reusable transform.\n",
        "\n",
        "In this example, we use it to tokenize lines into individual words, convert each word into lowercase, and count the occurance of each word.\n",
        "\n"
      ],
      "metadata": {
        "id": "UXen4r_h0wa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LowerTokenizeCountAndStrip(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | 'Split into Words' >> beam.ParDo(SplitIntoWords())\n",
        "                | 'Lowercase each Words' >> beam.Map(lambda x: x.lower())\n",
        "                | 'Strip each Word into AlphaNumeric' >> beam.Map(lambda x: re.sub(r'\\W+', '', x))\n",
        "                | 'Count Words' >> beam.combiners.Count.PerElement())\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "(p | 'Read from Text' >> beam.io.ReadFromText('input1.txt')\n",
        "   | 'Tokenize and Count' >> LowerTokenizeCountAndStrip()\n",
        "   | 'Write to Text' >> beam.io.WriteToText('output-composite-transform', file_name_suffix='.txt'))\n",
        "\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk8OT15Vtv3H",
        "outputId": "7bfafd6c-30ca-4f22-88ba-e26d2d38aa5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7d0f02990eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Windowing and Triggers**"
      ],
      "metadata": {
        "id": "-ystYle4p2zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In stream processing (and sometimes in batch processing with large datasets), data is often processed as it arrives, rather than waiting for a complete dataset. To handle this continuous flow of data effectively, two primary concepts are introduced in many stream processing systems, including Apache Beam: windowing and triggering.\n",
        "\n",
        "- **Windowing**:\n",
        "  - **Purpose**: To divide the unbounded, continuous stream of data into finite chunks or \"windows\" so that it can be processed.\n",
        "  - **Types**:\n",
        "    - Fixed Windows: Divide the data into fixed-size, non-overlapping chunks based on the event time. E.g., every 5 minutes.\n",
        "    - Sliding Windows: Divide the data into fixed-size chunks, but the start of each window \"slides\" over time, so windows can overlap. E.g., a window of size 10 minutes that starts every 5 minutes.\n",
        "    - Session Windows: Data is windowed based on periods of activity. A session window closes when it detects a gap in incoming data that's larger than a specified duration.\n",
        "    - Global Windows: The default windowing strategy in Beam. It places all data into a single, unbounded window.\n",
        "- **Triggering**:\n",
        "  - **Purpose**: To determine when the results of the windowed computations should be emitted. Without triggers, a windowed computation might only produce a result when the window is closed, but often we want results more frequently or under specific conditions.\n",
        "  - **Types**:\n",
        "    - Event Time Triggers: Fire based on the event time (the timestamp on the data itself).\n",
        "    - Processing Time Triggers: Fire based on the processing time (the time the data is processed by the system).\n",
        "    - Count Triggers: Fire after a certain number of data elements have been collected.\n",
        "    - Composite Triggers: Combine multiple triggers to form more complex conditions.\n",
        "  -**Accumulation Modes**:\n",
        "    - Discarding Mode: After a trigger fires, it discards all the accumulated data.\n",
        "    - Accumulating Mode: After a trigger fires, it retains the accumulated data and continues accumulating until the window closes.\n",
        "\n",
        "In this example, we simulate a continuous flow of data by providing multiple imput files. In this example the window is set to 1 second. This example also includes a AfterCount trigger. This means that for every window (which, based on the code, is 1 minute long), if there are 100 elements in that window, the trigger will fire, and the system will process and output the data for that window. If there are fewer than 100 elements, the window will not produce any output until it either gathers 100 elements or the window ends."
      ],
      "metadata": {
        "id": "A2Z7jLVN-62L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "from apache_beam.transforms.trigger import AfterCount\n",
        "from apache_beam import combiners\n",
        "\n",
        "class LowerTokenizeCountAndStrip(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | 'Split into Words' >> beam.ParDo(SplitIntoWords())\n",
        "                | 'Lowercase each Words' >> beam.Map(lambda x: x.lower())\n",
        "                | 'Strip each Word into AlphaNumeric' >> beam.Map(lambda x: re.sub(r'\\W+', '', x))\n",
        "                | 'Count Words' >> beam.combiners.Count.PerElement())\n",
        "\n",
        "file_paths = ['input1.txt', 'input2.txt', 'input3.txt']\n",
        "\n",
        "class SplitIntoWords(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        return re.findall(r'\\w+', element)\n",
        "\n",
        "window_size = 1  # example window size in minutes\n",
        "\n",
        "p = beam.Pipeline(options=PipelineOptions())\n",
        "\n",
        "counts = (\n",
        "    [p | f'Read file {i}' >> beam.io.ReadFromText(file_path) for i, file_path in enumerate(file_paths)]\n",
        "    | 'Flatten PCollections' >> beam.Flatten()\n",
        "    | 'Tokenize and Count' >> LowerTokenizeCountAndStrip()\n",
        "    | 'Window' >> beam.WindowInto(FixedWindows(window_size), trigger=AfterCount(100), accumulation_mode=beam.transforms.trigger.AccumulationMode.ACCUMULATING)\n",
        "    | 'Write results' >> beam.io.WriteToText('output-window-trigger', file_name_suffix='.txt')\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "p.run().wait_until_finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "dEDXYqUiuO_F",
        "outputId": "7e0f4a45-a9ac-4972-ac62-eff189910a46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-10d2f7c1-ddfe-465d-9c6b-0aef82c21735.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-10d2f7c1-ddfe-465d-9c6b-0aef82c21735.json']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DONE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}